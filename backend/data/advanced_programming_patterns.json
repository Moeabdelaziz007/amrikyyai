[
  {
    "id": "js-advanced-001",
    "title": "Advanced JavaScript Patterns and Techniques",
    "content": "## Modern JavaScript Advanced Patterns\n\n### 1. Advanced Async Patterns\n```javascript\n// Promise Composition and Error Handling\nclass AsyncTaskManager {\n  constructor() {\n    this.tasks = new Map();\n    this.retryConfig = { maxRetries: 3, delay: 1000 };\n  }\n\n  async executeWithRetry(taskFn, config = this.retryConfig) {\n    let lastError;\n    \n    for (let attempt = 1; attempt <= config.maxRetries; attempt++) {\n      try {\n        return await taskFn();\n      } catch (error) {\n        lastError = error;\n        \n        if (attempt === config.maxRetries) {\n          throw new Error(`Task failed after ${config.maxRetries} attempts: ${error.message}`);\n        }\n        \n        await this.delay(config.delay * attempt); // Exponential backoff\n      }\n    }\n  }\n\n  async parallel(tasks, { concurrency = 5, failFast = false } = {}) {\n    const results = [];\n    const errors = [];\n    \n    // Create semaphore for concurrency control\n    const semaphore = new Semaphore(concurrency);\n    \n    const executeTask = async (task, index) => {\n      await semaphore.acquire();\n      \n      try {\n        const result = await task();\n        results[index] = result;\n      } catch (error) {\n        errors[index] = error;\n        if (failFast) {\n          throw error;\n        }\n      } finally {\n        semaphore.release();\n      }\n    };\n\n    await Promise.all(\n      tasks.map((task, index) => executeTask(task, index))\n    );\n\n    return { results, errors };\n  }\n\n  delay(ms) {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n}\n\n// Semaphore implementation\nclass Semaphore {\n  constructor(capacity) {\n    this.capacity = capacity;\n    this.running = 0;\n    this.queue = [];\n  }\n\n  async acquire() {\n    return new Promise((resolve) => {\n      if (this.running < this.capacity) {\n        this.running++;\n        resolve();\n      } else {\n        this.queue.push(resolve);\n      }\n    });\n  }\n\n  release() {\n    this.running--;\n    if (this.queue.length > 0) {\n      this.running++;\n      const resolve = this.queue.shift();\n      resolve();\n    }\n  }\n}\n```\n\n### 2. Advanced Functional Programming\n```javascript\n// Functional Composition and Monads\nclass Maybe {\n  constructor(value) {\n    this.value = value;\n  }\n\n  static of(value) {\n    return new Maybe(value);\n  }\n\n  static nothing() {\n    return new Maybe(null);\n  }\n\n  isNothing() {\n    return this.value === null || this.value === undefined;\n  }\n\n  map(fn) {\n    return this.isNothing() ? Maybe.nothing() : Maybe.of(fn(this.value));\n  }\n\n  flatMap(fn) {\n    return this.isNothing() ? Maybe.nothing() : fn(this.value);\n  }\n\n  filter(predicate) {\n    return this.isNothing() || !predicate(this.value) \n      ? Maybe.nothing() \n      : this;\n  }\n\n  getOrElse(defaultValue) {\n    return this.isNothing() ? defaultValue : this.value;\n  }\n}\n\n// Pipe function for composition\nconst pipe = (...fns) => (value) => fns.reduce((acc, fn) => fn(acc), value);\n\n// Curry function\nconst curry = (fn) => {\n  return function curried(...args) {\n    if (args.length >= fn.length) {\n      return fn.apply(this, args);\n    } else {\n      return function(...args2) {\n        return curried.apply(this, args.concat(args2));\n      };\n    }\n  };\n};\n\n// Example usage\nconst add = curry((a, b) => a + b);\nconst multiply = curry((a, b) => a * b);\nconst subtract = curry((a, b) => a - b);\n\nconst calculate = pipe(\n  add(10),\n  multiply(2),\n  subtract(5)\n);\n\nconsole.log(calculate(5)); // ((5 + 10) * 2) - 5 = 25\n```\n\n### 3. Advanced Event Handling and Observer Pattern\n```javascript\nclass EventEmitter {\n  constructor() {\n    this.events = {};\n    this.maxListeners = 10;\n  }\n\n  on(event, listener) {\n    if (!this.events[event]) {\n      this.events[event] = [];\n    }\n    \n    if (this.events[event].length >= this.maxListeners) {\n      console.warn(`MaxListenersExceededWarning: ${this.maxListeners} listeners added for event '${event}'`);\n    }\n    \n    this.events[event].push(listener);\n    return this;\n  }\n\n  once(event, listener) {\n    const onceListener = (...args) => {\n      this.off(event, onceListener);\n      listener.apply(this, args);\n    };\n    \n    return this.on(event, onceListener);\n  }\n\n  off(event, listenerToRemove) {\n    if (!this.events[event]) return this;\n    \n    this.events[event] = this.events[event].filter(\n      listener => listener !== listenerToRemove\n    );\n    \n    return this;\n  }\n\n  emit(event, ...args) {\n    if (!this.events[event]) return false;\n    \n    this.events[event].forEach(listener => {\n      try {\n        listener.apply(this, args);\n      } catch (error) {\n        console.error(`Error in event listener for '${event}':`, error);\n      }\n    });\n    \n    return true;\n  }\n\n  removeAllListeners(event) {\n    if (event) {\n      delete this.events[event];\n    } else {\n      this.events = {};\n    }\n    return this;\n  }\n\n  listenerCount(event) {\n    return this.events[event] ? this.events[event].length : 0;\n  }\n}\n\n// Advanced Observable Pattern\nclass Observable {\n  constructor(subscribeFn) {\n    this.subscribe = subscribeFn;\n  }\n\n  static of(value) {\n    return new Observable(observer => {\n      observer.next(value);\n      observer.complete();\n    });\n  }\n\n  static fromArray(array) {\n    return new Observable(observer => {\n      array.forEach(item => observer.next(item));\n      observer.complete();\n    });\n  }\n\n  map(transformFn) {\n    return new Observable(observer => {\n      return this.subscribe({\n        next: value => observer.next(transformFn(value)),\n        error: err => observer.error(err),\n        complete: () => observer.complete()\n      });\n    });\n  }\n\n  filter(predicate) {\n    return new Observable(observer => {\n      return this.subscribe({\n        next: value => {\n          if (predicate(value)) {\n            observer.next(value);\n          }\n        },\n        error: err => observer.error(err),\n        complete: () => observer.complete()\n      });\n    });\n  }\n\n  take(count) {\n    return new Observable(observer => {\n      let taken = 0;\n      \n      return this.subscribe({\n        next: value => {\n          if (taken < count) {\n            observer.next(value);\n            taken++;\n            \n            if (taken === count) {\n              observer.complete();\n            }\n          }\n        },\n        error: err => observer.error(err),\n        complete: () => observer.complete()\n      });\n    });\n  }\n}\n```",
    "category": "javascript",
    "difficulty": "advanced",
    "language": "javascript",
    "tags": ["async-patterns", "functional-programming", "observables", "event-driven"]
  },
  {
    "id": "systems-001",
    "title": "System Design and Scalability Patterns",
    "content": "## Distributed Systems Design Patterns\n\n### 1. Circuit Breaker Pattern\n```python\nimport time\nimport threading\nfrom enum import Enum\nfrom typing import Callable, Any\nfrom dataclasses import dataclass\n\nclass CircuitState(Enum):\n    CLOSED = \"closed\"\n    OPEN = \"open\"\n    HALF_OPEN = \"half_open\"\n\n@dataclass\nclass CircuitBreakerConfig:\n    failure_threshold: int = 5\n    timeout: int = 60  # seconds\n    expected_exception: type = Exception\n    recovery_timeout: int = 30\n    success_threshold: int = 2\n\nclass CircuitBreaker:\n    def __init__(self, config: CircuitBreakerConfig):\n        self.config = config\n        self.state = CircuitState.CLOSED\n        self.failure_count = 0\n        self.success_count = 0\n        self.last_failure_time = None\n        self.lock = threading.Lock()\n    \n    def call(self, func: Callable, *args, **kwargs) -> Any:\n        with self.lock:\n            if self.state == CircuitState.OPEN:\n                if self._should_attempt_reset():\n                    self.state = CircuitState.HALF_OPEN\n                    self.success_count = 0\n                else:\n                    raise Exception(\"Circuit breaker is OPEN\")\n            \n            try:\n                result = func(*args, **kwargs)\n                self._on_success()\n                return result\n            except self.config.expected_exception as e:\n                self._on_failure()\n                raise e\n    \n    def _should_attempt_reset(self) -> bool:\n        return (\n            self.last_failure_time and\n            time.time() - self.last_failure_time >= self.config.recovery_timeout\n        )\n    \n    def _on_success(self):\n        self.failure_count = 0\n        \n        if self.state == CircuitState.HALF_OPEN:\n            self.success_count += 1\n            if self.success_count >= self.config.success_threshold:\n                self.state = CircuitState.CLOSED\n                self.success_count = 0\n    \n    def _on_failure(self):\n        self.failure_count += 1\n        self.last_failure_time = time.time()\n        \n        if self.failure_count >= self.config.failure_threshold:\n            self.state = CircuitState.OPEN\n\n# Example usage\nclass ExternalAPIClient:\n    def __init__(self):\n        self.circuit_breaker = CircuitBreaker(\n            CircuitBreakerConfig(\n                failure_threshold=3,\n                recovery_timeout=30,\n                expected_exception=ConnectionError\n            )\n        )\n    \n    def fetch_data(self, url: str):\n        return self.circuit_breaker.call(self._make_request, url)\n    \n    def _make_request(self, url: str):\n        # Simulate API call that might fail\n        import random\n        if random.random() < 0.3:  # 30% chance of failure\n            raise ConnectionError(\"API unavailable\")\n        return {\"data\": \"response from API\"}\n```\n\n### 2. Event Sourcing Pattern\n```python\nfrom abc import ABC, abstractmethod\nfrom typing import List, Any, Dict\nfrom datetime import datetime\nfrom dataclasses import dataclass, field\nimport json\nimport uuid\n\n@dataclass\nclass Event:\n    aggregate_id: str\n    event_type: str\n    event_data: Dict[str, Any]\n    event_version: int\n    timestamp: datetime = field(default_factory=datetime.utcnow)\n    event_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n\nclass EventStore(ABC):\n    @abstractmethod\n    def save_events(self, aggregate_id: str, events: List[Event], expected_version: int):\n        pass\n    \n    @abstractmethod\n    def get_events(self, aggregate_id: str, from_version: int = 0) -> List[Event]:\n        pass\n\nclass InMemoryEventStore(EventStore):\n    def __init__(self):\n        self.events: Dict[str, List[Event]] = {}\n        self.versions: Dict[str, int] = {}\n    \n    def save_events(self, aggregate_id: str, events: List[Event], expected_version: int):\n        current_version = self.versions.get(aggregate_id, 0)\n        \n        if current_version != expected_version:\n            raise Exception(f\"Concurrency conflict. Expected version {expected_version}, got {current_version}\")\n        \n        if aggregate_id not in self.events:\n            self.events[aggregate_id] = []\n        \n        for i, event in enumerate(events):\n            event.event_version = current_version + i + 1\n            self.events[aggregate_id].append(event)\n        \n        self.versions[aggregate_id] = current_version + len(events)\n    \n    def get_events(self, aggregate_id: str, from_version: int = 0) -> List[Event]:\n        aggregate_events = self.events.get(aggregate_id, [])\n        return [e for e in aggregate_events if e.event_version > from_version]\n\nclass AggregateRoot(ABC):\n    def __init__(self, aggregate_id: str = None):\n        self.aggregate_id = aggregate_id or str(uuid.uuid4())\n        self.version = 0\n        self.uncommitted_events: List[Event] = []\n    \n    def apply_event(self, event: Event):\n        self._handle_event(event)\n        self.version = event.event_version\n    \n    def raise_event(self, event_type: str, event_data: Dict[str, Any]):\n        event = Event(\n            aggregate_id=self.aggregate_id,\n            event_type=event_type,\n            event_data=event_data,\n            event_version=self.version + len(self.uncommitted_events) + 1\n        )\n        \n        self.uncommitted_events.append(event)\n        self.apply_event(event)\n    \n    def mark_events_as_committed(self):\n        self.uncommitted_events.clear()\n    \n    def load_from_history(self, events: List[Event]):\n        for event in events:\n            self.apply_event(event)\n    \n    @abstractmethod\n    def _handle_event(self, event: Event):\n        pass\n\n# Example: User Aggregate\nclass User(AggregateRoot):\n    def __init__(self, aggregate_id: str = None):\n        super().__init__(aggregate_id)\n        self.email = None\n        self.name = None\n        self.is_active = False\n    \n    def create_user(self, email: str, name: str):\n        if self.email is not None:\n            raise Exception(\"User already exists\")\n        \n        self.raise_event(\"UserCreated\", {\n            \"email\": email,\n            \"name\": name\n        })\n    \n    def activate_user(self):\n        if not self.email:\n            raise Exception(\"User does not exist\")\n        \n        if self.is_active:\n            raise Exception(\"User is already active\")\n        \n        self.raise_event(\"UserActivated\", {})\n    \n    def change_email(self, new_email: str):\n        if not self.email:\n            raise Exception(\"User does not exist\")\n        \n        self.raise_event(\"UserEmailChanged\", {\n            \"old_email\": self.email,\n            \"new_email\": new_email\n        })\n    \n    def _handle_event(self, event: Event):\n        if event.event_type == \"UserCreated\":\n            self.email = event.event_data[\"email\"]\n            self.name = event.event_data[\"name\"]\n            self.is_active = False\n        elif event.event_type == \"UserActivated\":\n            self.is_active = True\n        elif event.event_type == \"UserEmailChanged\":\n            self.email = event.event_data[\"new_email\"]\n\n# Repository for Event Sourced Aggregates\nclass EventSourcedRepository:\n    def __init__(self, event_store: EventStore):\n        self.event_store = event_store\n    \n    def save(self, aggregate: AggregateRoot):\n        if aggregate.uncommitted_events:\n            self.event_store.save_events(\n                aggregate.aggregate_id,\n                aggregate.uncommitted_events,\n                aggregate.version - len(aggregate.uncommitted_events)\n            )\n            aggregate.mark_events_as_committed()\n    \n    def get_by_id(self, aggregate_id: str, aggregate_class) -> AggregateRoot:\n        events = self.event_store.get_events(aggregate_id)\n        if not events:\n            return None\n        \n        aggregate = aggregate_class(aggregate_id)\n        aggregate.load_from_history(events)\n        return aggregate\n```\n\n### 3. CQRS with Event Sourcing\n```python\nclass UserProjection:\n    def __init__(self):\n        self.users = {}  # In real app, this would be a database\n    \n    def handle_user_created(self, event: Event):\n        user_data = {\n            'id': event.aggregate_id,\n            'email': event.event_data['email'],\n            'name': event.event_data['name'],\n            'is_active': False,\n            'created_at': event.timestamp\n        }\n        self.users[event.aggregate_id] = user_data\n    \n    def handle_user_activated(self, event: Event):\n        if event.aggregate_id in self.users:\n            self.users[event.aggregate_id]['is_active'] = True\n    \n    def handle_user_email_changed(self, event: Event):\n        if event.aggregate_id in self.users:\n            self.users[event.aggregate_id]['email'] = event.event_data['new_email']\n    \n    def get_user(self, user_id: str):\n        return self.users.get(user_id)\n    \n    def get_all_users(self):\n        return list(self.users.values())\n\nclass EventHandler:\n    def __init__(self, projection: UserProjection):\n        self.projection = projection\n        self.handlers = {\n            'UserCreated': self.projection.handle_user_created,\n            'UserActivated': self.projection.handle_user_activated,\n            'UserEmailChanged': self.projection.handle_user_email_changed\n        }\n    \n    def handle(self, event: Event):\n        handler = self.handlers.get(event.event_type)\n        if handler:\n            handler(event)\n\n# Usage Example\nevent_store = InMemoryEventStore()\nrepository = EventSourcedRepository(event_store)\nprojection = UserProjection()\nevent_handler = EventHandler(projection)\n\n# Create and save user\nuser = User()\nuser.create_user(\"john@example.com\", \"John Doe\")\nuser.activate_user()\n\n# Save to event store\nrepository.save(user)\n\n# Update projections\nfor event in user.uncommitted_events:\n    event_handler.handle(event)\n```",
    "category": "systems-design",
    "difficulty": "expert",
    "language": "python",
    "tags": ["circuit-breaker", "event-sourcing", "cqrs", "distributed-systems", "microservices"]
  },
  {
    "id": "performance-001",
    "title": "Performance Optimization and Profiling",
    "content": "## Advanced Performance Optimization Techniques\n\n### 1. Memory Management and Profiling\n```python\nimport sys\nimport gc\nimport tracemalloc\nimport cProfile\nimport pstats\nfrom functools import wraps\nfrom typing import Any, Callable\nimport psutil\nimport time\n\nclass MemoryProfiler:\n    def __init__(self):\n        self.snapshots = []\n    \n    def start_tracing(self):\n        tracemalloc.start()\n        self.snapshots.clear()\n    \n    def take_snapshot(self, description: str = \"\"):\n        if tracemalloc.is_tracing():\n            snapshot = tracemalloc.take_snapshot()\n            self.snapshots.append((description, snapshot))\n            return snapshot\n        return None\n    \n    def compare_snapshots(self, idx1: int = 0, idx2: int = -1):\n        if len(self.snapshots) < 2:\n            return None\n        \n        _, snapshot1 = self.snapshots[idx1]\n        _, snapshot2 = self.snapshots[idx2]\n        \n        top_stats = snapshot2.compare_to(snapshot1, 'lineno')\n        \n        print(f\"Memory comparison between snapshots {idx1} and {idx2}:\")\n        for stat in top_stats[:10]:\n            print(stat)\n    \n    def get_current_memory_usage(self):\n        process = psutil.Process()\n        memory_info = process.memory_info()\n        return {\n            'rss': memory_info.rss,  # Resident Set Size\n            'vms': memory_info.vms,  # Virtual Memory Size\n            'percent': process.memory_percent()\n        }\n\n# Performance monitoring decorator\ndef performance_monitor(include_memory=True, include_profiling=False):\n    def decorator(func: Callable) -> Callable:\n        @wraps(func)\n        def wrapper(*args, **kwargs) -> Any:\n            # Start monitoring\n            start_time = time.time()\n            \n            if include_memory:\n                process = psutil.Process()\n                memory_before = process.memory_info().rss\n            \n            if include_profiling:\n                profiler = cProfile.Profile()\n                profiler.enable()\n            \n            try:\n                # Execute function\n                result = func(*args, **kwargs)\n                \n                # Calculate metrics\n                execution_time = time.time() - start_time\n                \n                if include_memory:\n                    memory_after = process.memory_info().rss\n                    memory_delta = memory_after - memory_before\n                    \n                    print(f\"Function '{func.__name__}' performance:\")\n                    print(f\"  Execution time: {execution_time:.4f} seconds\")\n                    print(f\"  Memory before: {memory_before / 1024 / 1024:.2f} MB\")\n                    print(f\"  Memory after: {memory_after / 1024 / 1024:.2f} MB\")\n                    print(f\"  Memory delta: {memory_delta / 1024 / 1024:.2f} MB\")\n                \n                if include_profiling:\n                    profiler.disable()\n                    stats = pstats.Stats(profiler)\n                    stats.sort_stats('cumulative')\n                    print(f\"\\nProfiling results for '{func.__name__}':\")\n                    stats.print_stats(10)  # Top 10 functions\n                \n                return result\n                \n            except Exception as e:\n                print(f\"Function '{func.__name__}' failed: {e}\")\n                raise\n        \n        return wrapper\n    return decorator\n\n# Example usage\n@performance_monitor(include_memory=True, include_profiling=True)\ndef memory_intensive_function():\n    # Simulate memory-intensive operation\n    large_list = [i for i in range(1000000)]\n    \n    # Some processing\n    result = sum(x * x for x in large_list if x % 2 == 0)\n    \n    # Cleanup\n    del large_list\n    gc.collect()\n    \n    return result\n```\n\n### 2. Algorithm Optimization and Complexity Analysis\n```python\nimport time\nimport functools\nfrom typing import List, Dict, Any, Callable\nfrom collections import defaultdict\nimport heapq\n\nclass AlgorithmAnalyzer:\n    def __init__(self):\n        self.results = defaultdict(list)\n    \n    def time_complexity_test(self, algorithm: Callable, input_generator: Callable, sizes: List[int]):\n        \"\"\"Test algorithm with different input sizes to analyze time complexity\"\"\"\n        \n        for size in sizes:\n            test_input = input_generator(size)\n            \n            # Measure execution time\n            start_time = time.perf_counter()\n            result = algorithm(test_input)\n            end_time = time.perf_counter()\n            \n            execution_time = end_time - start_time\n            \n            self.results[algorithm.__name__].append({\n                'size': size,\n                'time': execution_time,\n                'result_size': len(result) if hasattr(result, '__len__') else 1\n            })\n    \n    def analyze_growth_rate(self, algorithm_name: str):\n        \"\"\"Analyze the growth rate of an algorithm\"\"\"\n        data = self.results[algorithm_name]\n        \n        if len(data) < 2:\n            return \"Insufficient data for analysis\"\n        \n        # Calculate growth ratios\n        ratios = []\n        for i in range(1, len(data)):\n            size_ratio = data[i]['size'] / data[i-1]['size']\n            time_ratio = data[i]['time'] / data[i-1]['time']\n            ratios.append(time_ratio / size_ratio)\n        \n        avg_ratio = sum(ratios) / len(ratios)\n        \n        # Estimate complexity\n        if avg_ratio < 1.5:\n            complexity = \"O(n) - Linear\"\n        elif avg_ratio < 2.5:\n            complexity = \"O(n log n) - Linearithmic\"\n        elif avg_ratio < 4:\n            complexity = \"O(n²) - Quadratic\"\n        else:\n            complexity = \"O(n³) or worse - Polynomial/Exponential\"\n        \n        return f\"Estimated complexity: {complexity} (avg ratio: {avg_ratio:.2f})\"\n\n# Optimized algorithms examples\nclass OptimizedAlgorithms:\n    @staticmethod\n    def binary_search_optimized(arr: List[int], target: int) -> int:\n        \"\"\"Optimized binary search with bounds checking\"\"\"\n        left, right = 0, len(arr) - 1\n        \n        while left <= right:\n            # Avoid potential overflow\n            mid = left + (right - left) // 2\n            \n            if arr[mid] == target:\n                return mid\n            elif arr[mid] < target:\n                left = mid + 1\n            else:\n                right = mid - 1\n        \n        return -1\n    \n    @staticmethod\n    def merge_sort_optimized(arr: List[int]) -> List[int]:\n        \"\"\"Optimized merge sort with insertion sort for small arrays\"\"\"\n        def insertion_sort(arr, left, right):\n            for i in range(left + 1, right + 1):\n                key = arr[i]\n                j = i - 1\n                while j >= left and arr[j] > key:\n                    arr[j + 1] = arr[j]\n                    j -= 1\n                arr[j + 1] = key\n        \n        def merge(arr, left, mid, right):\n            # Create temp arrays\n            left_arr = arr[left:mid + 1]\n            right_arr = arr[mid + 1:right + 1]\n            \n            i = j = 0\n            k = left\n            \n            while i < len(left_arr) and j < len(right_arr):\n                if left_arr[i] <= right_arr[j]:\n                    arr[k] = left_arr[i]\n                    i += 1\n                else:\n                    arr[k] = right_arr[j]\n                    j += 1\n                k += 1\n            \n            # Copy remaining elements\n            while i < len(left_arr):\n                arr[k] = left_arr[i]\n                i += 1\n                k += 1\n            \n            while j < len(right_arr):\n                arr[k] = right_arr[j]\n                j += 1\n                k += 1\n        \n        def merge_sort_helper(arr, left, right):\n            if right - left <= 10:  # Use insertion sort for small arrays\n                insertion_sort(arr, left, right)\n            elif left < right:\n                mid = left + (right - left) // 2\n                merge_sort_helper(arr, left, mid)\n                merge_sort_helper(arr, mid + 1, right)\n                merge(arr, left, mid, right)\n        \n        if len(arr) <= 1:\n            return arr\n        \n        arr_copy = arr.copy()\n        merge_sort_helper(arr_copy, 0, len(arr_copy) - 1)\n        return arr_copy\n    \n    @staticmethod\n    def dijkstra_optimized(graph: Dict[str, List[tuple]], start: str) -> Dict[str, int]:\n        \"\"\"Optimized Dijkstra's algorithm using priority queue\"\"\"\n        distances = defaultdict(lambda: float('inf'))\n        distances[start] = 0\n        \n        # Priority queue: (distance, node)\n        pq = [(0, start)]\n        visited = set()\n        \n        while pq:\n            current_distance, current_node = heapq.heappop(pq)\n            \n            if current_node in visited:\n                continue\n            \n            visited.add(current_node)\n            \n            # Early termination if we've visited all nodes\n            if len(visited) == len(graph):\n                break\n            \n            for neighbor, weight in graph.get(current_node, []):\n                if neighbor not in visited:\n                    new_distance = current_distance + weight\n                    \n                    if new_distance < distances[neighbor]:\n                        distances[neighbor] = new_distance\n                        heapq.heappush(pq, (new_distance, neighbor))\n        \n        return dict(distances)\n\n# Caching and memoization for performance\nclass CacheManager:\n    def __init__(self, max_size: int = 128):\n        self.max_size = max_size\n        self.cache = {}\n        self.access_order = []\n    \n    def lru_cache(self, func: Callable) -> Callable:\n        \"\"\"LRU cache implementation\"\"\"\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Create cache key\n            key = str(args) + str(sorted(kwargs.items()))\n            \n            if key in self.cache:\n                # Move to end (most recently used)\n                self.access_order.remove(key)\n                self.access_order.append(key)\n                return self.cache[key]\n            \n            # Compute result\n            result = func(*args, **kwargs)\n            \n            # Add to cache\n            if len(self.cache) >= self.max_size:\n                # Remove least recently used\n                lru_key = self.access_order.pop(0)\n                del self.cache[lru_key]\n            \n            self.cache[key] = result\n            self.access_order.append(key)\n            \n            return result\n        \n        return wrapper\n    \n    def clear_cache(self):\n        self.cache.clear()\n        self.access_order.clear()\n\n# Example usage\nif __name__ == \"__main__\":\n    # Algorithm analysis\n    analyzer = AlgorithmAnalyzer()\n    optimized_algos = OptimizedAlgorithms()\n    \n    # Test merge sort performance\n    def generate_random_list(size):\n        import random\n        return [random.randint(1, 1000) for _ in range(size)]\n    \n    test_sizes = [100, 500, 1000, 5000, 10000]\n    analyzer.time_complexity_test(\n        optimized_algos.merge_sort_optimized,\n        generate_random_list,\n        test_sizes\n    )\n    \n    print(analyzer.analyze_growth_rate('merge_sort_optimized'))\n```",
    "category": "performance",
    "difficulty": "expert",
    "language": "python",
    "tags": ["optimization", "profiling", "algorithms", "memory-management", "complexity-analysis"]
  }
]
